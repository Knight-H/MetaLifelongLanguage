{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, gc, os, pickle, csv\n",
    "\n",
    "import datasets.utils\n",
    "import models.utils\n",
    "from models.cls_oml_ori_v2 import OML\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import higher\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_order_mapping = {\n",
    "    1: [2, 0, 3, 1, 4],\n",
    "    2: [3, 4, 0, 1, 2],\n",
    "    3: [2, 4, 1, 3, 0],\n",
    "    4: [0, 2, 1, 4, 3]\n",
    "}\n",
    "n_classes = 33\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "# model_path = \"/data/model_runs/original_oml/aOML-order1-2022-07-18/OML-order1-id4-2022-07-18_17-53-13.518612.pt\"\n",
    "# model_path = \"/data/model_runs/original_oml/aOML-order1-inlr002-2022-07-31/OML-order1-id4-2022-07-31_14-53-46.456804.pt\"\n",
    "# model_path = \"/data/model_runs/original_oml/aOML-order1-inlr005-2022-07-31/OML-order1-id4-2022-07-31_18-47-41.477968.pt\"\n",
    "# model_path = \"/data/model_runs/original_oml/aOML-order1-inlr005-up20-2022-08-01/OML-order1-id4-2022-08-01_14-45-55.869765.pt\"\n",
    "# model_path = \"/data/model_runs/original_oml/aOML-order1-inlr010-2022-07-31/OML-order1-id4-2022-07-31_21-18-36.241546.pt\"\n",
    "# model_path = \"/data/model_runs/original_oml/aOML-order1-inlr020-2022-08-16/OML-order1-id4-2022-08-16_11-37-19.424113.pt\"\n",
    "model_path = \"/data/model_runs/original_oml/aOML-order1-ori/OML-order1-id4-2023-04-25_22-37-58.874941.pt\"\n",
    "\n",
    "\n",
    "# memory_path = \"/data/model_runs/original_oml/aOML-order1-2022-07-18/OML-order1-id4-2022-07-18_17-53-13.518639_memory.pickle\"\n",
    "# memory_path = \"/data/model_runs/original_oml/aOML-order1-inlr002-2022-07-31/OML-order1-id4-2022-07-31_14-53-46.456828_memory.pickle\"\n",
    "# memory_path = \"/data/model_runs/original_oml/aOML-order1-inlr005-2022-07-31/OML-order1-id4-2022-07-31_18-47-41.477992_memory.pickle\"\n",
    "# memory_path = \"/data/model_runs/original_oml/aOML-order1-inlr005-up20-2022-08-01/OML-order1-id4-2022-08-01_14-45-55.869797_memory.pickle\"\n",
    "# memory_path = \"/data/model_runs/original_oml/aOML-order1-inlr010-2022-07-31/OML-order1-id4-2022-07-31_21-18-36.241572_memory.pickle\"\n",
    "# memory_path = \"/data/model_runs/original_oml/aOML-order1-inlr020-2022-08-16/OML-order1-id4-2022-08-16_11-37-19.424139_memory.pickle\"\n",
    "memory_path = \"/data/model_runs/original_oml/aOML-order1-ori/OML-order1-id4-2023-04-25_22-37-58.874970_memory.pickle\"\n",
    "\n",
    "\n",
    "use_db_cache = True\n",
    "cache_dir = 'tmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"order\": 1,\n",
    "    \"n_epochs\": 1,\n",
    "    \"lr\": 3e-5,\n",
    "    \"inner_lr\": 0.001*10,\n",
    "    \"meta_lr\": 3e-5,\n",
    "    \"model\": \"roberta\", # changed from bert\n",
    "    \"learner\": \"oml\",\n",
    "    \"mini_batch_size\": 16,\n",
    "    \"updates\": 5*1,\n",
    "    \"write_prob\": 1.0,\n",
    "    \"max_length\": 448,\n",
    "    \"seed\": 42,\n",
    "    \"replay_rate\": 0.01,\n",
    "    \"replay_every\": 9600,\n",
    "    \"pln\": \"1fc\"\n",
    "}\n",
    "updates = args[\"updates\"]\n",
    "mini_batch_size = args[\"mini_batch_size\"]\n",
    "order = args[\"order\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(args[\"seed\"])\n",
    "random.seed(args[\"seed\"])\n",
    "np.random.seed(args[\"seed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the datasets\n",
      "Finished loading all the datasets\n"
     ]
    }
   ],
   "source": [
    "print('Loading the datasets')\n",
    "test_datasets = []\n",
    "for dataset_id in dataset_order_mapping[order]:\n",
    "    test_dataset_file = os.path.join(cache_dir, f\"{dataset_id}.cache\")\n",
    "    if os.path.exists(test_dataset_file):\n",
    "        with open(test_dataset_file, 'rb') as f:\n",
    "            test_dataset = pickle.load(f)\n",
    "    else:\n",
    "        test_dataset = datasets.utils.get_dataset_test(\"\", dataset_id)\n",
    "        print('Loaded {}'.format(test_dataset.__class__.__name__))\n",
    "        test_dataset = datasets.utils.offset_labels(test_dataset)\n",
    "        pickle.dump(test_dataset, open( test_dataset_file, \"wb\" ), protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        print(f\"Pickle saved at {test_dataset_file}\")\n",
    "    test_datasets.append(test_dataset)\n",
    "print('Finished loading all the datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-14 10:07:57,009 - transformers.tokenization_utils_base - INFO - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "2023-09-14 10:07:57,014 - transformers.tokenization_utils_base - INFO - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-09-14 10:07:58,370 - transformers.configuration_utils - INFO - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n",
      "2023-09-14 10:07:58,378 - transformers.configuration_utils - INFO - Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "2023-09-14 10:07:58,441 - transformers.modeling_utils - INFO - loading weights file https://cdn.huggingface.co/roberta-base-pytorch_model.bin from cache at /root/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
      "2023-09-14 10:08:11,146 - transformers.modeling_utils - INFO - All model checkpoint weights were used when initializing RobertaModel.\n",
      "\n",
      "2023-09-14 10:08:11,154 - transformers.modeling_utils - INFO - All the weights of RobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use RobertaModel for predictions without further training.\n",
      "2023-09-14 10:08:17,150 - OML-Log - INFO - Loaded TransformerRLN as RLN\n",
      "2023-09-14 10:08:17,158 - OML-Log - INFO - Loaded LinearPLN as PLN\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using OML as learner\n"
     ]
    }
   ],
   "source": [
    "learner = OML(device=device, n_classes=n_classes, **args)\n",
    "print('Using {} as learner'.format(learner.__class__.__name__))\n",
    "learner.load_model(model_path)\n",
    "with open(memory_path, 'rb') as f:\n",
    "    learner.memory = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "\n",
    "Select specific column index per row\n",
    "https://stackoverflow.com/questions/23435782/numpy-selecting-specific-column-index-per-row-by-using-a-list-of-indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader, updates, mini_batch_size):\n",
    "    learner.rln.eval()\n",
    "    learner.pln.train()\n",
    "    \n",
    "    support_set = []\n",
    "    for _ in range(updates):\n",
    "        text, labels = learner.memory.read_batch(batch_size=mini_batch_size)\n",
    "        support_set.append((text, labels))\n",
    "    \n",
    "    with higher.innerloop_ctx(learner.pln, learner.inner_optimizer,\n",
    "                              copy_initial_weights=False, track_higher_grads=False) as (fpln, diffopt):\n",
    "\n",
    "        # Inner loop\n",
    "        task_predictions, task_labels = [], []\n",
    "        support_loss = []\n",
    "        for text, labels in support_set:\n",
    "            labels = torch.tensor(labels).to(device)\n",
    "            input_dict = learner.rln.encode_text(text)\n",
    "            _repr = learner.rln(input_dict)\n",
    "            output = fpln(_repr)\n",
    "            loss = learner.loss_fn(output, labels)\n",
    "            diffopt.step(loss)\n",
    "            pred = models.utils.make_prediction(output.detach())\n",
    "            support_loss.append(loss.item())\n",
    "            task_predictions.extend(pred.tolist())\n",
    "            task_labels.extend(labels.tolist())\n",
    "\n",
    "        acc, prec, rec, f1 = models.utils.calculate_metrics(task_predictions, task_labels)\n",
    "\n",
    "        print('Support set metrics: Loss = {:.4f}, accuracy = {:.4f}, precision = {:.4f}, '\n",
    "                    'recall = {:.4f}, F1 score = {:.4f}'.format(np.mean(support_loss), acc, prec, rec, f1))\n",
    "\n",
    "        all_losses, all_predictions, all_labels, all_label_conf = [], [], [], []\n",
    "\n",
    "        for text, labels in dataloader:\n",
    "            labels = torch.tensor(labels).to(device)\n",
    "            input_dict = learner.rln.encode_text(text)\n",
    "            with torch.no_grad():\n",
    "                _repr = learner.rln(input_dict)\n",
    "                output = fpln(_repr) # Output has size of torch.Size([16, 33]) [BATCH, CLASSES]\n",
    "                loss = learner.loss_fn(output, labels)\n",
    "            loss = loss.item()\n",
    "            # print(output.detach().size())\n",
    "            # output.detach().max(-1) max on each Batch, which will return [0] max, [1] indices\n",
    "            output_softmax = F.softmax(output, -1)\n",
    "            label_conf = output_softmax[np.arange(len(output_softmax)), labels] # Select labels in the softmax of 33 classes\n",
    "            \n",
    "            pred = models.utils.make_prediction(output.detach())\n",
    "            \n",
    "            all_losses.append(loss)\n",
    "            all_predictions.extend(pred.tolist())\n",
    "            all_labels.extend(labels.tolist())\n",
    "            all_label_conf.extend(label_conf.tolist())\n",
    "\n",
    "    acc, prec, rec, f1 = models.utils.calculate_metrics(all_predictions, all_labels)\n",
    "    print('Test metrics: Loss = {:.4f}, accuracy = {:.4f}, precision = {:.4f}, recall = {:.4f}, '\n",
    "                'F1 score = {:.4f}'.format(np.mean(all_losses), acc, prec, rec, f1))\n",
    "    return acc, prec, rec, f1, all_predictions, all_labels, all_label_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Testing on test set starts here----------\n",
      "Testing on YelpDataset\n",
      "Support set metrics: Loss = 0.4177, accuracy = 0.8875, precision = 0.8988, recall = 0.8923, F1 score = 0.8913\n",
      "Test metrics: Loss = 1.1012, accuracy = 0.5596, precision = 0.6217, recall = 0.5603, F1 score = 0.5693\n",
      "Testing on AGNewsDataset\n",
      "Support set metrics: Loss = 0.7551, accuracy = 0.7500, precision = 0.8318, recall = 0.8225, F1 score = 0.8036\n",
      "Test metrics: Loss = 0.3922, accuracy = 0.8876, precision = 0.9004, recall = 0.8876, F1 score = 0.8935\n",
      "Testing on DBPediaDataset\n",
      "Support set metrics: Loss = 0.9310, accuracy = 0.7000, precision = 0.7356, recall = 0.7445, F1 score = 0.7290\n",
      "Test metrics: Loss = 0.1178, accuracy = 0.9817, precision = 0.9832, recall = 0.9818, F1 score = 0.9824\n",
      "Testing on AmazonDataset\n",
      "Support set metrics: Loss = 0.6217, accuracy = 0.7875, precision = 0.8046, recall = 0.8228, F1 score = 0.8061\n",
      "Test metrics: Loss = 1.1856, accuracy = 0.5507, precision = 0.6240, recall = 0.5510, F1 score = 0.5673\n",
      "Testing on YahooAnswersDataset\n",
      "Support set metrics: Loss = 0.8101, accuracy = 0.7625, precision = 0.8408, recall = 0.8426, F1 score = 0.8116\n",
      "Test metrics: Loss = 0.8417, accuracy = 0.7462, precision = 0.7501, recall = 0.7478, F1 score = 0.7449\n",
      "\n",
      "COPY PASTA - not really but ok\n",
      "0.5596052631578947\n",
      "0.8876315789473684\n",
      "0.9817105263157895\n",
      "0.5506578947368421\n",
      "0.7461842105263158\n",
      "\n",
      "Overall test metrics: Accuracy = 0.7452, precision = 0.7759, recall = 0.7457, F1 score = 0.7515\n"
     ]
    }
   ],
   "source": [
    "print('----------Testing on test set starts here----------')\n",
    "\n",
    "accuracies, precisions, recalls, f1s = [], [], [], []\n",
    "# Data for Visualization: [data_idx, label, label_conf, pred]\n",
    "data_for_visual = []\n",
    "\n",
    "for test_dataset in test_datasets:\n",
    "    print('Testing on {}'.format(test_dataset.__class__.__name__))\n",
    "    test_dataloader = data.DataLoader(test_dataset, batch_size=mini_batch_size, shuffle=False,\n",
    "                                      collate_fn=datasets.utils.batch_encode)\n",
    "    acc, prec, rec, f1, all_pred, all_label, all_label_conf = evaluate(dataloader=test_dataloader, updates=updates, \n",
    "                                                                       mini_batch_size=mini_batch_size)\n",
    "    \n",
    "    data_ids = [test_dataset.__class__.__name__ + str(i) for i in range(len(all_label))]\n",
    "    data_for_visual.extend(list(zip(data_ids, all_label, all_label_conf, all_pred)))\n",
    "#     print(data_ids)\n",
    "#     print(all_label)\n",
    "#     raise Exception(\"BREAKPOINT\")\n",
    "    \n",
    "    accuracies.append(acc)\n",
    "    precisions.append(prec)\n",
    "    recalls.append(rec)\n",
    "    f1s.append(f1)\n",
    "\n",
    "print()\n",
    "print(\"COPY PASTA - not really but ok\")\n",
    "for row in accuracies:\n",
    "    print(row)\n",
    "print()\n",
    "print('Overall test metrics: Accuracy = {:.4f}, precision = {:.4f}, recall = {:.4f}, '\n",
    "            'F1 score = {:.4f}'.format(np.mean(accuracies), np.mean(precisions), np.mean(recalls), np.mean(f1s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done writing CSV File at /data/model_runs/original_oml/aOML-order1-ori/OML-order1-id4-2023-04-25_22-37-58.874941_update5_results_old.csv\n"
     ]
    }
   ],
   "source": [
    "_model_path0 = os.path.splitext(model_path)[0]\n",
    "csv_filename = _model_path0 + \"_update\"+ str(updates) +\"_results_old.csv\"\n",
    "with open(csv_filename, 'w') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow([\"data_idx\", \"label\", \"label_conf\", \"pred\"])\n",
    "    csv_writer.writerows(data_for_visual)\n",
    "print(f\"Done writing CSV File at {csv_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metalifelong",
   "language": "python",
   "name": "metalifelong"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
