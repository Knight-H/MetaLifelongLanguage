{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a159a832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, gc, os, pickle, csv, time, re\n",
    "import torch\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "import datasets.utils\n",
    "from datasets.lifelong_fewrel_dataset import LifelongFewRelDataset\n",
    "from models.rel_baseline import Baseline\n",
    "import models.utils\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05bf1e2",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "267f68f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06010b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL_PATH = \"/data/model_runs/original_oml/\"\n",
    "model_name = \"Baseline-order5-id4-2023-05-28_10-52-41.172695.pt\"\n",
    "model_path = os.path.join(BASE_MODEL_PATH, model_name)\n",
    "\n",
    "data_dir = '/data/omler_data/LifelongFewRel'\n",
    "relation_file = os.path.join(data_dir, 'relation_name.txt')\n",
    "validation_file = os.path.join(data_dir, 'val_data.txt')\n",
    "relation_names = datasets.utils.read_relations(relation_file)\n",
    "val_data = datasets.utils.read_rel_data(validation_file)\n",
    "val_dataset = LifelongFewRelDataset(val_data, relation_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1a24c56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fill',\n",
       " ['place', 'served', 'by', 'transport', 'hub'],\n",
       " ['mountain', 'range'],\n",
       " ['religion'],\n",
       " ['participating', 'team'],\n",
       " ['contains', 'administrative', 'territorial', 'entity'],\n",
       " ['head', 'of', 'government'],\n",
       " ['country', 'of', 'citizenship'],\n",
       " ['original', 'network'],\n",
       " ['heritage', 'designation'],\n",
       " ['performer'],\n",
       " ['participant', 'of'],\n",
       " ['position', 'held'],\n",
       " ['has', 'part'],\n",
       " ['location', 'of', 'formation'],\n",
       " ['located', 'on', 'terrain', 'feature'],\n",
       " ['architect'],\n",
       " ['country', 'of', 'origin'],\n",
       " ['publisher'],\n",
       " ['director'],\n",
       " ['father'],\n",
       " ['developer'],\n",
       " ['military', 'branch'],\n",
       " ['mouth', 'of', 'the', 'watercourse'],\n",
       " ['nominated', 'for'],\n",
       " ['movement'],\n",
       " ['successful', 'candidate'],\n",
       " ['followed', 'by'],\n",
       " ['manufacturer'],\n",
       " ['instance', 'of'],\n",
       " ['after', 'a', 'work', 'by'],\n",
       " ['member', 'of', 'political', 'party'],\n",
       " ['licensed', 'to', 'broadcast', 'to'],\n",
       " ['headquarters', 'location'],\n",
       " ['sibling'],\n",
       " ['instrument'],\n",
       " ['country'],\n",
       " ['occupation'],\n",
       " ['residence'],\n",
       " ['work', 'location'],\n",
       " ['subsidiary'],\n",
       " ['participant'],\n",
       " ['operator'],\n",
       " ['characters'],\n",
       " ['occupant'],\n",
       " ['genre'],\n",
       " ['operating', 'system'],\n",
       " ['owned', 'by'],\n",
       " ['platform'],\n",
       " ['tributary'],\n",
       " ['winner'],\n",
       " ['said', 'to', 'be', 'the', 'same', 'as'],\n",
       " ['composer'],\n",
       " ['league'],\n",
       " ['record', 'label'],\n",
       " ['distributor'],\n",
       " ['screenwriter'],\n",
       " ['sports', 'season', 'of', 'league', 'or', 'competition'],\n",
       " ['taxon', 'rank'],\n",
       " ['location'],\n",
       " ['field', 'of', 'work'],\n",
       " ['language', 'of', 'work', 'or', 'name'],\n",
       " ['applies', 'to', 'jurisdiction'],\n",
       " ['notable', 'work'],\n",
       " ['located', 'in', 'the', 'administrative', 'territorial', 'entity'],\n",
       " ['crosses'],\n",
       " ['original', 'language', 'of', 'work'],\n",
       " ['competition', 'class'],\n",
       " ['part', 'of'],\n",
       " ['sport'],\n",
       " ['constellation'],\n",
       " ['position', 'played', 'on', 'team', 'speciality'],\n",
       " ['located', 'in', 'or', 'next', 'to', 'body', 'of', 'water'],\n",
       " ['voice', 'type'],\n",
       " ['follows'],\n",
       " ['spouse'],\n",
       " ['military', 'rank'],\n",
       " ['mother'],\n",
       " ['member', 'of'],\n",
       " ['child'],\n",
       " ['main', 'subject']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relation_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4d5097",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f78b9107",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'n_epochs': 1, \n",
    "    'lr': 0.0004, \n",
    "    'inner_lr': 0.001, \n",
    "    'meta_lr': 3e-05, \n",
    "    'model': 'roberta', \n",
    "    'learner': 'sequential', \n",
    "    'mini_batch_size': 4, \n",
    "    'updates': 5, \n",
    "    'write_prob': 1.0, \n",
    "    'max_length': 64, \n",
    "    'seed': 42, \n",
    "    'replay_rate': 0.01, \n",
    "    'order': 5, \n",
    "    'num_clusters': 10, \n",
    "    'replay_every': 1600, \n",
    "    'model_dir': '/data/model_runs/original_oml'\n",
    "}\n",
    "mini_batch_size = args[\"mini_batch_size\"]\n",
    "model_name = args['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f28ae4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(args[\"seed\"])\n",
    "random.seed(args[\"seed\"])\n",
    "np.random.seed(args[\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba33a27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 08:42:58,036 - transformers.tokenization_utils_base - INFO - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "2023-05-29 08:42:58,039 - transformers.tokenization_utils_base - INFO - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-05-29 08:42:59,206 - transformers.configuration_utils - INFO - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n",
      "2023-05-29 08:42:59,210 - transformers.configuration_utils - INFO - Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "2023-05-29 08:42:59,262 - transformers.modeling_utils - INFO - loading weights file https://cdn.huggingface.co/roberta-base-pytorch_model.bin from cache at /root/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
      "2023-05-29 08:43:04,033 - transformers.modeling_utils - INFO - All model checkpoint weights were used when initializing RobertaModel.\n",
      "\n",
      "2023-05-29 08:43:04,044 - transformers.modeling_utils - INFO - All the weights of RobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use RobertaModel for predictions without further training.\n",
      "2023-05-29 08:43:07,853 - Baseline-Log - INFO - Loaded TransformerClsModel as the model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Baseline as learner\n"
     ]
    }
   ],
   "source": [
    "learner = Baseline(device=device, training_mode='sequential', **args)\n",
    "print('Using {} as learner'.format(learner.__class__.__name__))\n",
    "learner.load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7c855e",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b60aa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = data.DataLoader(val_dataset, batch_size=mini_batch_size, shuffle=False,\n",
    "                                  collate_fn=datasets.utils.rel_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76647c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████████████▌                                          | 998/2800 [01:10<02:08, 13.98it/s]/root/MetaLifelongLanguage/env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/root/MetaLifelongLanguage/env/lib/python3.8/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 36%|███████████████████████▎                                         | 1002/2800 [01:10<02:13, 13.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 metrics: Loss = nan, accuracy = 1.0000\n",
      "replicated_text\n",
      "after union with greece , thessaly became divided into four prefectures : larissa prefecture , magnesia prefecture , karditsa prefecture , and trikala prefecture .country\n",
      "after union with greece , thessaly became divided into four prefectures : larissa prefecture , magnesia prefecture , karditsa prefecture , and trikala prefecture .performer\n",
      "after union with greece , thessaly became divided into four prefectures : larissa prefecture , magnesia prefecture , karditsa prefecture , and trikala prefecture .developer\n",
      "after union with greece , thessaly became divided into four prefectures : larissa prefecture , magnesia prefecture , karditsa prefecture , and trikala prefecture .field of work\n",
      "after union with greece , thessaly became divided into four prefectures : larissa prefecture , magnesia prefecture , karditsa prefecture , and trikala prefecture .place served by transport hub\n",
      "tokenized text\n",
      "<s> Ġafter Ġunion Ġwith Ġg ree ce Ġ, Ġthe ss aly Ġbecame Ġdivided Ġinto Ġfour Ġpre fect ures Ġ: Ġlar issa Ġpre fecture Ġ, Ġmag nesia Ġpre fecture Ġ, Ġk ard its a Ġpre fecture Ġ, Ġand Ġtri k ala Ġpre fecture Ġ. </s> </s> Ġcountry </s>\n",
      "<s> Ġafter Ġunion Ġwith Ġg ree ce Ġ, Ġthe ss aly Ġbecame Ġdivided Ġinto Ġfour Ġpre fect ures Ġ: Ġlar issa Ġpre fecture Ġ, Ġmag nesia Ġpre fecture Ġ, Ġk ard its a Ġpre fecture Ġ, Ġand Ġtri k ala Ġpre fecture Ġ. </s> </s> Ġperformer </s>\n",
      "<s> Ġafter Ġunion Ġwith Ġg ree ce Ġ, Ġthe ss aly Ġbecame Ġdivided Ġinto Ġfour Ġpre fect ures Ġ: Ġlar issa Ġpre fecture Ġ, Ġmag nesia Ġpre fecture Ġ, Ġk ard its a Ġpre fecture Ġ, Ġand Ġtri k ala Ġpre fecture Ġ. </s> </s> Ġdeveloper </s>\n",
      "<s> Ġafter Ġunion Ġwith Ġg ree ce Ġ, Ġthe ss aly Ġbecame Ġdivided Ġinto Ġfour Ġpre fect ures Ġ: Ġlar issa Ġpre fecture Ġ, Ġmag nesia Ġpre fecture Ġ, Ġk ard its a Ġpre fecture Ġ, Ġand Ġtri k ala Ġpre fecture Ġ. </s> </s> Ġfield Ġof Ġwork </s>\n",
      "<s> Ġafter Ġunion Ġwith Ġg ree ce Ġ, Ġthe ss aly Ġbecame Ġdivided Ġinto Ġfour Ġpre fect ures Ġ: Ġlar issa Ġpre fecture Ġ, Ġmag nesia Ġpre fecture Ġ, Ġk ard its a Ġpre fecture Ġ, Ġand Ġtri k ala Ġpre fecture Ġ. </s> </s> Ġplace Ġserved Ġby Ġtransport Ġhub </s>\n",
      "RankingLabel:  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "PRED:  [0, 0, 0]\n",
      "ANS:  [0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|██████████████████████████████████████████████▍                  | 2002/2800 [02:19<00:57, 13.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 metrics: Loss = nan, accuracy = 1.0000\n",
      "replicated_text\n",
      "it was soon expanded with the addition of the lord privy seal , arthur greenwood , and the chancellor of the exchequer , hugh dalton .position held\n",
      "it was soon expanded with the addition of the lord privy seal , arthur greenwood , and the chancellor of the exchequer , hugh dalton .said to be the same as\n",
      "it was soon expanded with the addition of the lord privy seal , arthur greenwood , and the chancellor of the exchequer , hugh dalton .developer\n",
      "it was soon expanded with the addition of the lord privy seal , arthur greenwood , and the chancellor of the exchequer , hugh dalton .sports season of league or competition\n",
      "it was soon expanded with the addition of the lord privy seal , arthur greenwood , and the chancellor of the exchequer , hugh dalton .member of\n",
      "tokenized text\n",
      "<s> Ġit Ġwas Ġsoon Ġexpanded Ġwith Ġthe Ġaddition Ġof Ġthe Ġlord Ġpriv y Ġseal Ġ, Ġar thur Ġgreen wood Ġ, Ġand Ġthe Ġchancellor Ġof Ġthe Ġex che quer Ġ, Ġh ugh Ġd al ton Ġ. </s> </s> Ġposition Ġheld </s>\n",
      "<s> Ġit Ġwas Ġsoon Ġexpanded Ġwith Ġthe Ġaddition Ġof Ġthe Ġlord Ġpriv y Ġseal Ġ, Ġar thur Ġgreen wood Ġ, Ġand Ġthe Ġchancellor Ġof Ġthe Ġex che quer Ġ, Ġh ugh Ġd al ton Ġ. </s> </s> Ġsaid Ġto Ġbe Ġthe Ġsame Ġas </s>\n",
      "<s> Ġit Ġwas Ġsoon Ġexpanded Ġwith Ġthe Ġaddition Ġof Ġthe Ġlord Ġpriv y Ġseal Ġ, Ġar thur Ġgreen wood Ġ, Ġand Ġthe Ġchancellor Ġof Ġthe Ġex che quer Ġ, Ġh ugh Ġd al ton Ġ. </s> </s> Ġdeveloper </s>\n",
      "<s> Ġit Ġwas Ġsoon Ġexpanded Ġwith Ġthe Ġaddition Ġof Ġthe Ġlord Ġpriv y Ġseal Ġ, Ġar thur Ġgreen wood Ġ, Ġand Ġthe Ġchancellor Ġof Ġthe Ġex che quer Ġ, Ġh ugh Ġd al ton Ġ. </s> </s> Ġsports Ġseason Ġof Ġleague Ġor Ġcompetition </s>\n",
      "<s> Ġit Ġwas Ġsoon Ġexpanded Ġwith Ġthe Ġaddition Ġof Ġthe Ġlord Ġpriv y Ġseal Ġ, Ġar thur Ġgreen wood Ġ, Ġand Ġthe Ġchancellor Ġof Ġthe Ġex che quer Ġ, Ġh ugh Ġd al ton Ġ. </s> </s> Ġmember Ġof </s>\n",
      "RankingLabel:  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "PRED:  [0, 0, 0]\n",
      "ANS:  [0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 2800/2800 [03:15<00:00, 14.35it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_losses, all_predictions, all_labels = [], [], []\n",
    "learner.model.eval()\n",
    "_iter = 0\n",
    "for text, label, candidates in tqdm(dataloader):\n",
    "    replicated_text, replicated_relations, ranking_label = datasets.utils.replicate_rel_data(text, label, candidates)\n",
    "\n",
    "    add_prefix_space = False\n",
    "    if model_name == \"roberta\":\n",
    "        replicated_text = [ \" \".join(_t) for _t in replicated_text ]\n",
    "        replicated_relations = [ \" \".join(_t) for _t in replicated_relations ]\n",
    "        add_prefix_space = True\n",
    "\n",
    "    with torch.no_grad():\n",
    "        input_dict = learner.model.encode_text(list(zip(replicated_text, replicated_relations)),add_prefix_space)\n",
    "        output = learner.model(input_dict)\n",
    "\n",
    "    pred, true_labels = models.utils.make_rel_prediction(output, ranking_label)\n",
    "    all_predictions.extend(pred.tolist())\n",
    "    all_labels.extend(true_labels.tolist())\n",
    "\n",
    "\n",
    "    _iter += 1\n",
    "    if _iter % 1000 == 0:\n",
    "        acc = models.utils.calculate_accuracy(all_predictions, all_labels)\n",
    "        print('Epoch {} metrics: Loss = {:.4f}, accuracy = {:.4f}'.format(1, np.mean(all_losses), acc))\n",
    "        print(\"replicated_text\")\n",
    "        for text, relation in zip(replicated_text[:5], replicated_relations[:5]):\n",
    "            print(text + relation)\n",
    "        print(\"tokenized text\")\n",
    "        for ids in input_dict['input_ids'][:5]:\n",
    "            print(\" \".join(learner.model.tokenizer.convert_ids_to_tokens([_id for _id in ids if _id != 1])))\n",
    "        print(\"RankingLabel: \", ranking_label)\n",
    "        print(\"PRED: \", pred.tolist())\n",
    "        print(\"ANS: \", true_labels.tolist())\n",
    "\n",
    "acc = models.utils.calculate_accuracy(all_predictions, all_labels)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5003e8d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text, label, candidates = next(dataloader.__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee21d8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['in',\n",
       "  'august',\n",
       "  '2016',\n",
       "  ',',\n",
       "  'duplass',\n",
       "  'brothers',\n",
       "  'announced',\n",
       "  'another',\n",
       "  'television',\n",
       "  'project',\n",
       "  '\"',\n",
       "  'room',\n",
       "  '104',\n",
       "  '\"',\n",
       "  'to',\n",
       "  'air',\n",
       "  'on',\n",
       "  'hbo',\n",
       "  'in',\n",
       "  '2017',\n",
       "  '.'],\n",
       " ['in',\n",
       "  'august',\n",
       "  '2016',\n",
       "  ',',\n",
       "  'duplass',\n",
       "  'brothers',\n",
       "  'announced',\n",
       "  'another',\n",
       "  'television',\n",
       "  'project',\n",
       "  '\"',\n",
       "  'room',\n",
       "  '104',\n",
       "  '\"',\n",
       "  'to',\n",
       "  'air',\n",
       "  'on',\n",
       "  'hbo',\n",
       "  'in',\n",
       "  '2017',\n",
       "  '.'],\n",
       " ['in',\n",
       "  'august',\n",
       "  '2016',\n",
       "  ',',\n",
       "  'duplass',\n",
       "  'brothers',\n",
       "  'announced',\n",
       "  'another',\n",
       "  'television',\n",
       "  'project',\n",
       "  '\"',\n",
       "  'room',\n",
       "  '104',\n",
       "  '\"',\n",
       "  'to',\n",
       "  'air',\n",
       "  'on',\n",
       "  'hbo',\n",
       "  'in',\n",
       "  '2017',\n",
       "  '.'],\n",
       " ['in',\n",
       "  'august',\n",
       "  '2016',\n",
       "  ',',\n",
       "  'duplass',\n",
       "  'brothers',\n",
       "  'announced',\n",
       "  'another',\n",
       "  'television',\n",
       "  'project',\n",
       "  '\"',\n",
       "  'room',\n",
       "  '104',\n",
       "  '\"',\n",
       "  'to',\n",
       "  'air',\n",
       "  'on',\n",
       "  'hbo',\n",
       "  'in',\n",
       "  '2017',\n",
       "  '.'],\n",
       " ['in',\n",
       "  'august',\n",
       "  '2016',\n",
       "  ',',\n",
       "  'duplass',\n",
       "  'brothers',\n",
       "  'announced',\n",
       "  'another',\n",
       "  'television',\n",
       "  'project',\n",
       "  '\"',\n",
       "  'room',\n",
       "  '104',\n",
       "  '\"',\n",
       "  'to',\n",
       "  'air',\n",
       "  'on',\n",
       "  'hbo',\n",
       "  'in',\n",
       "  '2017',\n",
       "  '.'],\n",
       " ['in',\n",
       "  'august',\n",
       "  '2016',\n",
       "  ',',\n",
       "  'duplass',\n",
       "  'brothers',\n",
       "  'announced',\n",
       "  'another',\n",
       "  'television',\n",
       "  'project',\n",
       "  '\"',\n",
       "  'room',\n",
       "  '104',\n",
       "  '\"',\n",
       "  'to',\n",
       "  'air',\n",
       "  'on',\n",
       "  'hbo',\n",
       "  'in',\n",
       "  '2017',\n",
       "  '.'],\n",
       " ['in',\n",
       "  'august',\n",
       "  '2016',\n",
       "  ',',\n",
       "  'duplass',\n",
       "  'brothers',\n",
       "  'announced',\n",
       "  'another',\n",
       "  'television',\n",
       "  'project',\n",
       "  '\"',\n",
       "  'room',\n",
       "  '104',\n",
       "  '\"',\n",
       "  'to',\n",
       "  'air',\n",
       "  'on',\n",
       "  'hbo',\n",
       "  'in',\n",
       "  '2017',\n",
       "  '.'],\n",
       " ['in',\n",
       "  'august',\n",
       "  '2016',\n",
       "  ',',\n",
       "  'duplass',\n",
       "  'brothers',\n",
       "  'announced',\n",
       "  'another',\n",
       "  'television',\n",
       "  'project',\n",
       "  '\"',\n",
       "  'room',\n",
       "  '104',\n",
       "  '\"',\n",
       "  'to',\n",
       "  'air',\n",
       "  'on',\n",
       "  'hbo',\n",
       "  'in',\n",
       "  '2017',\n",
       "  '.'],\n",
       " ['in',\n",
       "  'august',\n",
       "  '2016',\n",
       "  ',',\n",
       "  'duplass',\n",
       "  'brothers',\n",
       "  'announced',\n",
       "  'another',\n",
       "  'television',\n",
       "  'project',\n",
       "  '\"',\n",
       "  'room',\n",
       "  '104',\n",
       "  '\"',\n",
       "  'to',\n",
       "  'air',\n",
       "  'on',\n",
       "  'hbo',\n",
       "  'in',\n",
       "  '2017',\n",
       "  '.'],\n",
       " ['in',\n",
       "  'august',\n",
       "  '2016',\n",
       "  ',',\n",
       "  'duplass',\n",
       "  'brothers',\n",
       "  'announced',\n",
       "  'another',\n",
       "  'television',\n",
       "  'project',\n",
       "  '\"',\n",
       "  'room',\n",
       "  '104',\n",
       "  '\"',\n",
       "  'to',\n",
       "  'air',\n",
       "  'on',\n",
       "  'hbo',\n",
       "  'in',\n",
       "  '2017',\n",
       "  '.'],\n",
       " ['in',\n",
       "  'august',\n",
       "  '2016',\n",
       "  ',',\n",
       "  'duplass',\n",
       "  'brothers',\n",
       "  'announced',\n",
       "  'another',\n",
       "  'television',\n",
       "  'project',\n",
       "  '\"',\n",
       "  'room',\n",
       "  '104',\n",
       "  '\"',\n",
       "  'to',\n",
       "  'air',\n",
       "  'on',\n",
       "  'hbo',\n",
       "  'in',\n",
       "  '2017',\n",
       "  '.']]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replicated_text, replicated_relations, ranking_label = datasets.utils.replicate_rel_data(text, label, candidates)\n",
    "replicated_text = replicated_text[:11]\n",
    "replicated_relations = replicated_relations[:11]\n",
    "ranking_label = ranking_label[:11]\n",
    "replicated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d80c0dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    input_dict = learner.model.encode_text(list(zip(replicated_text, replicated_relations)),add_prefix_space)\n",
    "    output = learner.model(input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "adaaf653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 64])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dict['input_ids'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f215e471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d2d796cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3018],\n",
       "        [-2.3018],\n",
       "        [-2.3018],\n",
       "        [-2.3018],\n",
       "        [-2.3018],\n",
       "        [-2.3018],\n",
       "        [-2.3018],\n",
       "        [-2.3018],\n",
       "        [-2.3018],\n",
       "        [-2.3018],\n",
       "        [-2.3018]], device='cuda:0')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cc59abfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0])\n",
      "tensor([0])\n"
     ]
    }
   ],
   "source": [
    "pred, true_labels = models.utils.make_rel_prediction(output, ranking_label)\n",
    "print(ranking_label)\n",
    "print(pred)\n",
    "print(true_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metalifelong",
   "language": "python",
   "name": "metalifelong"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
